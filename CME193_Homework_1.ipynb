{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CME193 - Assignment 1\n",
    "\n",
    "In this assignment, you'll be implementing and exploring properties of [Markov chains](https://en.wikipedia.org/wiki/Markov_chain). Don't worry if you aren't familiar with them -- this notebook will explain everything needed for the assignment.\n",
    "\n",
    "## Markov chains\n",
    "Markov chains are simple systems that are described by probabilistic rules at each time step. The best way to introduce Markov chains is with a simple example. Suppose we have a simple counter that can be set to any number between 0 and 5, including 0 and 5. It starts at some number, say 0. At every step, you flip a coin: if it is heads, then the counter increases by 1, and if it is tails, then the counter decreases by 1. The counter doesn't change if the counter is at 0 and we flip tails or if it is at 5 and we flip heads.\n",
    "\n",
    "Here is an example instance of this Markov chain:\n",
    " - Step 0. The counter is at 0.\n",
    " - Step 1. The coin lands on tails; the counter remains at 0.\n",
    " - Step 2. The coin lands on heads; the counter increases to 1.\n",
    " - Step 3. The coin lands on heads; the counter increases to 2.\n",
    " - Step 4. The coin lands on tails; the counter decreases to 1.\n",
    " - ...and so on.\n",
    "\n",
    "\n",
    "Mathematically, a Markov chain like this consists of a set of $n$ states (in our example, it is the 6 possible states of the counter), as well as probabilistic rules that indicates the probability of landing in each of the different states after each step. The rule, one for each state, consists of $n$ probabilities that sum to $1$.\n",
    "\n",
    "For example, if the counter is currently set to 3, the rule would be represented by the vector\n",
    "$$\n",
    "\\begin{pmatrix} 0 \\\\ 0 \\\\ 0.5 \\\\ 0 \\\\ 0.5 \\\\ 0 \\end{pmatrix}\n",
    "$$\n",
    "This is because after the next step, we have 0 probability of ending up in state 0, 0 probability of state 1, 0.5 probability of state 2, 0 probability of state 3, 0.5 probability of state 4, and so on.\n",
    "\n",
    "In NumPy, this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.array([0, 0, 0.5, 0, 0.5, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have one of these probability vectors for each of our states 0 through 5. If we stack these horizontally into a matrix, we end up with what's called the *transition matrix* of the Markov chain. In our case, it looks like this:\n",
    "$$\n",
    "T = \\begin{pmatrix}\n",
    "0.5 & 0.5 & 0 & 0 & 0 & 0 \\\\\n",
    "0.5 & 0 & 0.5 & 0 & 0 & 0 \\\\\n",
    "0 & 0.5 & 0 & 0.5 & 0 & 0 \\\\\n",
    "0 & 0 & 0.5 & 0 & 0.5 & 0 \\\\\n",
    "0 & 0 & 0 & 0.5 & 0 & 0.5  \\\\\n",
    "0 & 0 & 0 & 0 & 0.5 & 0.5 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "In general, we can represent Markov chains with a transition matrix $T$ of size $(n,n)$, where the column $j$ will be the probabilistic rule vector for the state $j$. (Here we are assuming that the states are numbered $0$ to $n-1$. The element $T_{ij}$ represents the probability that we end up in state $i$ if we are currently in state $j$ after a single step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Transition matrix\n",
    "\n",
    "For the rest of this assignment, we will consider the following Markov chain. It has $n$ states, numbered $0$ through $n-1$. If the current state is $n-1$, then it stays in the same state of $n-1$ (with probability 1). Otherwise, if current state is $i$, with probability 0.8, it goes to state $i+1$, and with probability 0.2, it falls back to state $i = 0$. Intuitively, at every step there is an 80% chance that it climbs up by 1, but a 20% chance that it falls down all the way. However, if it does reach the state $n-1$, it stays there forever.\n",
    "\n",
    "Write a function that returns the transition matrix for this Markov chain, given the number of states $n$ as an argument. You are **not** allowed to use any loops for this question; instead, use NumPy indexing to fill in your matrix. You can assume that $n \\ge 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def transition_matrix(n):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "transition_matrix(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your function, check that the above returns \n",
    "```\n",
    "array([[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0. ],\n",
    "       [0.8, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
    "       [0. , 0.8, 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
    "       [0. , 0. , 0.8, 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
    "       [0. , 0. , 0. , 0.8, 0. , 0. , 0. , 0. , 0. , 0. ],\n",
    "       [0. , 0. , 0. , 0. , 0.8, 0. , 0. , 0. , 0. , 0. ],\n",
    "       [0. , 0. , 0. , 0. , 0. , 0.8, 0. , 0. , 0. , 0. ],\n",
    "       [0. , 0. , 0. , 0. , 0. , 0. , 0.8, 0. , 0. , 0. ],\n",
    "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.8, 0. , 0. ],\n",
    "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. , 0.8, 1. ]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Simulation\n",
    "\n",
    "In this question, we will simulate this Markov chain. That is, we want a sequence of states drawn according to the rules of the Markov chain. Here is one sample of 20 steps drawn from the Markov chain in the previous question, starting from the 0 state.\n",
    "\n",
    "```[0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9, 9]```\n",
    "\n",
    "Write a function that returns one such sample for each call. It should take the transition matrix `tm`, number of steps to run for `k`, and a starting state `s0`. It should return a list of `k+1` states, including the starting state. Because each simulation will be random, we expect to get different results every time.\n",
    "\n",
    "*Hint:* look into using `np.random.choice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def sample(tm, k, s0):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below code to test out some of the samples. It samples 5 simulations of the Markov chain and plots them. The plot should show that most trajectories have reached the final state after 100 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TESTING\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tm = transition_matrix(10)\n",
    "for i in range(5):\n",
    "    states = sample(tm, k=100, s0=0)\n",
    "    plt.plot(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Average state over time\n",
    "\n",
    "After each step, the counter increases by 1 or falls back to 0. We want to know how the average state changes over time.\n",
    "\n",
    "1. Create a transition matrix for $n = 25$.\n",
    "2. Sample 1000 trajectories of 100 steps using the `sample` function you wrote in Question 2.\n",
    "3. Compute the average state (over the 1000 samples) for each time step.\n",
    "4. Plot the average state as a function of the time step.\n",
    "\n",
    "*Hint:* You should see a plot where the average climbs quickly at first but then slows down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Propagation of probabilities\n",
    "\n",
    "Suppose we are interested in the probability of being in each state after running the Markov chain for $k$ steps. For example, for the above Markov chain, suppose we want to know: what is the probablity that the state $n-1$ has been reached after 30 steps.\n",
    "\n",
    "Luckily, this is fairly easy to calculate using matrix multiplication. An amazing property of the transition matrix is as follows. Let $p_j$ be the vector of probabilites at step $j$. That is, the $i$th entry of $p_j$ is the probability that the state is $i$ at step $j$. Then if $T$ is the transition matrix, then $p_{j+1}$ is related to $p_j$ by the following matrix vector product:\n",
    "$$ p_{j+1} =  Tp_j $$ We will not prove this result here, but it should make sense if you spend some time thinking about what matrix multiplication is doing here, especially interpreting it as taking a linear combination of columns.\n",
    "\n",
    "Therefore, if someone gives you a starting vector of probabilities $p_0$ describing the initial state distribution, then the probability distribution after $k$ steps is given by multiplying by the transition matrix $k$ times:\n",
    "\n",
    "$$ p_{k} =  T^{k}p_0 $$\n",
    "In our example Markov chain, if the state always starts at 0, then $p_0$ is the vector with $1$ in the first entry and $0$ everywhere else, since it starts at the first state with probability $1$.\n",
    "\n",
    "Write a function which, given a transition matrix `tm`, number of steps `k`, and a vector `p0` describing an initial state distribution, return the distribution after `k` steps of the Markov chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def propagate(tm, k, p0):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING\n",
    "tm = transition_matrix(10)\n",
    "p0 = np.zeros(10)\n",
    "p0[0] = 1\n",
    "pk = propagate(tm, k=30, p0=p0)\n",
    "pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code should return :\n",
    "\n",
    "```\n",
    "array([0.0816156 , 0.06787354, 0.05644353, 0.04694437, 0.03904617,\n",
    "       0.03247669, 0.02701094, 0.02246264, 0.01867741, 0.6074491 ])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Empirical comparison\n",
    "Simulate the distribution of states after 100 steps using `sample`, and compare it with the result returned by `propagate`.\n",
    "\n",
    "1. Create a transition matrix for $n = 25$.\n",
    "2. Sample 1000 trajectories of 100 steps using `sample`, and record the last state for each trajectory in a separate list.\n",
    "3. Plot a histogram of final states.\n",
    "4. Use the function `propagate` that you wrote to compute the theoretical distribution after 100 steps.\n",
    "5. Plot the theoretical distribution in the same plot and verify that it matches with the histogram.\n",
    "\n",
    "*Hint:*\n",
    "1. For the the histogram, you can set the bins manually so that there is one bin for each state. You can do this by setting the `bins` argument in `plt.hist` to be `[-0.5, 0.5, 1.5, 2.5, 3.5, ...]`. This way, the 0 state lands in the first bin, the 1 state lands in the second, etc.\n",
    "\n",
    "2. The propagate functions returns a probability distribution, so you need to multiply it with the number of samples for it to be comparable to the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: Analysis\n",
    "After each step, the probability of being in the final state slowly increases. At some point, this probability will cross 50%. How many steps does it take for the probability of being in the final state to be at least 0.5? \n",
    "\n",
    "Write code that computes the answer, as a function of the number of states `n`.\n",
    "\n",
    "*Hint:* Use a while loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def num_steps(n):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the number of steps required for $n$ ranging from 10 to 40. In addition to plotting with `plt.plot` as normal, also plot using `plt.semilogy` in a separate figure. (What does this function do, and what does the resulting plot tell you?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission instructions\n",
    "\n",
    "Save this notebook (`CME193_Homework_1.ipynb`), and submit it on Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
